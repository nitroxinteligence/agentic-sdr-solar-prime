# Relat√≥rio de Diagn√≥stico: Desvio de Fluxo do Agente

## 1. Resumo do Diagn√≥stico

O agente falha em seguir o fluxo de conversa√ß√£o definido no prompt (`prompt-agente.md`) porque a arquitetura atual cria um **conflito de instru√ß√µes**. O c√≥digo gera um "mini-prompt" din√¢mico que compete com o prompt principal (system prompt), fazendo com que o modelo de linguagem (LLM) ignore as regras do fluxo espec√≠fico e recorra a um comportamento gen√©rico e inadequado.

## 2. An√°lise da Inconsist√™ncia (Di√°logo vs. Prompt)

O desvio √© evidente no di√°logo fornecido:

1.  **Escolha do Fluxo**: O usu√°rio escolhe a op√ß√£o 3, "Compra de energia com desconto", ativando o **FLUXO C**.
2.  **Primeira Pergunta (Correta)**: O agente segue o script e pergunta: `Hoje voc√™ j√° recebe algum tipo de desconto na conta de luz?`
3.  **Resposta do Usu√°rio**: O usu√°rio responde `ainda nao`.
4.  **Ponto de Falha (Incorreto)**: Neste momento, o script do **FLUXO C** para a condi√ß√£o `SE N√ÉO TEM DESCONTO` √© claro e direto:
    > 2. "Entendi! Quanto voc√™ paga na conta de luz?"
    > 3. [Calcular] "Com nosso desconto de 20%..."

    O agente **ignora completamente** esta instru√ß√£o. Em vez disso, ele faz uma pergunta gen√©rica e proibida pelas regras: `Entendi... O que te impede de fechar neg√≥cio com a Solarprime hoje?`.
5.  **Perda Total de Contexto**: A partir da√≠, o agente abandona o fluxo, come√ßando a falar sobre a hist√≥ria da empresa e fazendo perguntas gen√©ricas, como se a conversa estivesse recome√ßando.

## 3. Causa Raiz: Por que o Agente se Desvia?

A investiga√ß√£o do c√≥digo revela tr√™s causas interligadas:

### Causa 1: Conflito de Prompts (C√≥digo vs. Arquivo `prompt-agente.md`)

Este √© o problema central. O m√©todo `_build_prompt` em `app/agents/agentic_sdr_refactored.py` constr√≥i um prompt de contexto din√¢mico a cada turno da conversa. Este "mini-prompt" inclui informa√ß√µes como `A√ß√£o recomendada: conversar`.

Quando o LLM recebe as instru√ß√µes, ele v√™:
1.  **Prompt Principal (Longo)**: O conte√∫do completo de `prompt-agente.md` com as regras detalhadas dos fluxos.
2.  **Mini-Prompt de Contexto (Curto e Imediato)**: Uma instru√ß√£o curta e direta gerada pelo c√≥digo, como `A√ß√£o recomendada: conversar`.

O modelo, especialmente quando a resposta do usu√°rio √© simples como "ainda nao", d√° mais peso ao "mini-prompt" imediato e ignora as regras complexas do prompt principal. A instru√ß√£o gen√©rica `A√ß√£o recomendada: conversar` o leva a improvisar em vez de seguir o script.

### Causa 2: Complexidade e Redund√¢ncia Excessiva do Prompt

O arquivo `prompt-agente.md` √© muito longo e detalhado. Ele cont√©m m√∫ltiplas se√ß√µes, regras repetidas e uma estrutura que, embora clara para um humano, √© dif√≠cil para um LLM seguir perfeitamente em todos os turnos da conversa, especialmente quando recebe instru√ß√µes conflitantes do c√≥digo.

### Causa 3: An√°lise de Contexto Gen√©rica

O `ContextAnalyzer` classifica a resposta "ainda nao" com uma inten√ß√£o e a√ß√£o gen√©ricas (ex: `conversa`). Essa classifica√ß√£o alimenta o "mini-prompt" problem√°tico, refor√ßando o desvio do fluxo correto.

## 4. Plano de A√ß√£o Corretivo (Foco na Simplifica√ß√£o)

Seguindo o princ√≠pio de que "o simples funciona sempre", a solu√ß√£o √© eliminar a fonte do conflito e simplificar as instru√ß√µes para o LLM.

### A√ß√£o I: Centralizar e Simplificar o Prompt (A Solu√ß√£o Principal)

O objetivo √© ter uma **√∫nica fonte da verdade** para as instru√ß√µes do agente.

1.  **Remover a Gera√ß√£o Din√¢mica de Prompt**: O m√©todo `_build_prompt` em `agentic_sdr_refactored.py` deve ser eliminado ou drasticamente simplificado. Ele n√£o deve mais gerar instru√ß√µes como "A√ß√£o recomendada". O √∫nico prompt enviado ao LLM deve ser o hist√≥rico da conversa.

2.  **Refatorar e Simplificar `prompt-agente.md`**: O prompt deve ser reescrito para ser mais direto e menos verboso. A l√≥gica de qual fluxo seguir deve ser clara e concisa, confiando que o LLM √© capaz de seguir um fluxo a partir do hist√≥rico da conversa.

    **Exemplo de Prompt Refatorado (Conceito):**

    ```markdown
    # HELEN VIEIRA - CONSULTORA SOLARPRIME 

    ## üéØ IDENTIDADE
    Voc√™ √© Helen Vieira, consultora de energia solar da SolarPrime. Seu objetivo √© qualificar leads e agendar reuni√µes com o especialista, Leonardo. Seja profissional, emp√°tica e amig√°vel. Use o nome do lead com modera√ß√£o. NUNCA use emojis.

    ## ‚ö° REGRA DE OURO: FLUXO CONVERSACIONAL
    Siga o fluxo de forma estrita. N√ÉO pule etapas. N√ÉO improvise.

    --- 

    ### EST√ÅGIO 0: In√≠cio
    - Se for o primeiro contato, se apresente e pergunte o nome: "Bom dia! Tudo bem? Me chamo Helen Vieira, sou consultora da Solarprime. Antes de come√ßarmos, como posso te chamar?"
    - **Transi√ß√£o**: Ap√≥s obter o nome, v√° para o EST√ÅGIO 1.

    --- 

    ### EST√ÅGIO 1: Apresenta√ß√£o
    - Apresente as 4 solu√ß√µes numeradas e pergunte qual interessa ao lead.
    - **Transi√ß√£o**: Com base na resposta, siga o FLUXO espec√≠fico (A, B, C ou D).

    --- 

    ### EST√ÅGIO 2: Qualifica√ß√£o (Fluxos)

    **SE FLUXO C (Compra com Desconto):**
    1.  Pergunte: "Voc√™ j√° recebe algum desconto na conta de luz?"
    2.  **Se a resposta for N√ÉO**: Pergunte o valor da conta. Ex: "Entendi! E qual o valor m√©dio da sua conta de luz?"
    3.  **Se a resposta for SIM**: Pergunte os detalhes do desconto. Ex: "Legal! E qual o valor sem o desconto e a porcentagem que voc√™ recebe?"
    4.  Continue o fluxo at√© o agendamento.

    **(Definir os outros fluxos A, B, D de forma similar e concisa)**

    --- 

    ### ‚ö†Ô∏è REGRAS GERAIS
    - **NUNCA** anuncie a√ß√µes ("vou calcular"). Responda com o resultado.
    - **NUNCA** pergunte "O que te impede de fechar?".
    - **SEMPRE** termine suas respostas com a pr√≥xima pergunta do fluxo.
    ```

### A√ß√£o II: Refinar a L√≥gica do Agente

1.  **Modificar `AgenticSDR.process_message`**: A chamada para `_build_prompt` deve ser removida. O prompt enviado ao `ModelManager` deve ser apenas o hist√≥rico da conversa. O `system_prompt` ser√° a vers√£o simplificada e refatorada do `prompt-agente.md`.
2.  **Ajustar `ContextAnalyzer`**: A an√°lise de contexto ainda √© √∫til para m√©tricas e logging, mas seu resultado **n√£o deve mais ser injetado no prompt** enviado ao LLM.

## 5. Benef√≠cios Esperados

- **Confiabilidade**: Ao remover o "mini-prompt" conflitante, o LLM ter√° uma √∫nica fonte de instru√ß√µes, aumentando drasticamente a probabilidade de seguir o fluxo corretamente.
- **Simplicidade**: Um prompt mais curto e direto √© mais f√°cil para o LLM processar e para os humanos manterem.
- **Performance**: Menos l√≥gica de c√≥digo para construir prompts resulta em um processamento ligeiramente mais r√°pido a cada turno.